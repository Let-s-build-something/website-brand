<resources>
  <string name="app_name">Augmy</string>

  <string name="website_footer">¬© %1$d Augmy Interactive</string>

  <string name="landing_header_heading">The new era of communication</string>
  <string name="landing_header_content">Talk online like you do in real life. Digital communication, reflective of the physical you, with agency in your hands.</string>

  <string name="landing_social_circle_heading">People are not ones and zeros.</string>
  <string name="landing_social_circle_text">Friend list? Followers? Does that really represent your social life? Friend or not friend? Forget about shallow meaningless labels. Now you can have your social space with depth in mind.</string>

  <string name="landing_messages_heading">Regular chat</string>
  <string name="landing_messages_text">Billions of people all over the world are being misunderstood and can't express themselves.\n\nPeople want to express themselves while messaging but there was no natural ways of showing that.</string>
  <string name="landing_message_0">how are you?</string>
  <string name="landing_message_1">I'm okay ü§∑</string>
  <string name="landing_message_2">You sure? After yesterday...</string>
  <string name="landing_message_3">I'm okay</string>
  <string name="landing_message_4">Okay</string>

  <string name="landing_messages_enhanced_heading">Powered by Augmy</string>
  <string name="landing_messages_enhanced_text">Imagine being understood in how you said it, not just what you said. We invent new ways for expressing what you feel beyond what you type.</string>
  <string name="landing_message_0_enhanced">how are you?</string>
  <string name="landing_message_1_enhanced">I'm okay ü§∑</string>
  <string name="landing_message_2_enhanced">Dude I really didn't mean it, I'm sorry...</string>
  <string name="landing_message_3_enhanced">Oh, I thought you did it purposefully. It's alright</string>
  <string name="landing_message_4_enhanced">cool cool cool üòÑ</string>
  <string name="landing_message_5_enhanced">beer tomorrow?</string>
  <string name="landing_message_6_enhanced">you bet</string>


  <string name="landing_block_0_heading">Rediscover the colors of communicatio</string>
  <string name="landing_block_0_content">Longing to understand how your loved one abroad is feeling? Don't know how to say how you feel? Want to feel close? Augmy is made for that.</string>

  <string name="landing_block_1_heading">Allow your digital body to speak up</string>
  <string name="landing_block_1_content">Your digital nonverbal communication is as important as your physical. You don't have to ponder which emoji best expresses your feelings anymore; be understood without overthinking.</string>

  <string name="landing_block_2_heading">It wasn't made for you</string>
  <string name="landing_block_2_content">Sometimes, expressing yourself can be challenging, and there are moments when you may simply lack the energy to explain. What you are using to chat with others wasn't meant for this. Augmy messenger is.</string>

  <string name="landing_block_3_heading">Communication matters</string>
  <string name="landing_block_3_content">If you want to understand someone better ‚Äî or help them understand you ‚Äî we‚Äôre here for that. Give it a shot, the people around you matter.</string>

  <string name="landing_block_demo_heading">Peek into the future of social spaces</string>

  <string name="landing_footer_heading">The problem statement</string>
  <string name="landing_footer_content">Messaging online as we know it is not enough‚Äîit lacks nuance in how we express ourselves, in the way we move, in the way we talk, and fails at synchronizing us with others. We often rely on oversimplified keywords and impersonal emojis or curate the impressions others may have of us, leaving the true expressions behind.
    It's time for online messaging that truly conveys how we mean it‚Äînot just what we type.</string>
  <string name="landing_footer_action">X‚Äîdoubt</string>

  <string name="landing_download_button">Download now.</string>
  <string name="landing_download_not_distributed">You can't register to open beta quite yet. Follow us on social media sites and we'll make sure you know once it's ready for you.</string>

  <string name="category_family">Family</string>
  <string name="category_peers">Peers</string>
  <string name="category_community">Community</string>
  <string name="category_contacts">Contacts</string>
  <string name="category_public">Public</string>

  <string name="toolbar_action_about_business">Business</string>
  <string name="toolbar_action_about_research">Research</string>
  <string name="toolbar_action_about">About</string>
  <string name="toolbar_action_contacts">Contacts</string>

  <string name="contacts_workplace">Workplace</string>
  <string name="contacts_workplace_value">Prague, Czechia</string>
  <string name="contacts_email">Email</string>
  <string name="kofi_link_text">Support us</string>
  <string name="contacts_email_value">info@augmy.org</string>
  <string name="contacts_twitter">https://www.twitter.com/AugmyInteractiv</string>
  <string name="contacts_instagram">https://www.instagram.com/augmy_interactive</string>
  <string name="contacts_linkedin">https://www.linkedin.com/company/augmy-interactive</string>
  <string name="contacts_bluesky">https://bsky.app/profile/augmyinteractive.bsky.social</string>
  <string name="contacts_kofi">https://ko-fi.com/augmy</string>
  <string name="contacts_discord">https://discord.gg/TFn8u9AE</string>
  <string name="contacts_discord_tag">A discord server</string>
  <string name="contacts_twitter_tag">@AugmyInteractiv</string>
  <string name="contacts_instagram_tag">@augmy_interactive</string>
  <string name="contacts_linkedin_tag">@augmy-interactive</string>
  <string name="contacts_bluesky_tag">@augmyinteractive.bsky.social</string>

  <string name="about_content">Short story long, this is why we do what we do. Our motivation lies between these lines.</string>
  <string name="about_header_summary">Summary</string>
  <string name="about_content_summary">We are incredibly social beings, we like to communicate and interact with others, no matter the reason. Nowadays, this happens online, particularly via instant messaging apps, forums like Reddit, social media, or comment sections. Communicating online is relatively easy and efficient, yet it doesn't seem to be us communicating, but the online versions of us - it's the GIFs, stickers, avatars, emojis, phrases and words who represent us. Not to mention the attention one must put into finding the best way to express themselves. Finding the right combinations of emojis, imagining how it would be perceived, editing what doesn't fit and so on.</string>
  <string name="about_header_introduction">Why is this important? (Introduction)</string>
  <string name="about_content_introduction_0">Nearly every fourth person uses WhatsApp alone. Communication online is more relevant than ever, and we are getting in line with that. From online therapy, governmental inquiries, messaging companies via live chats, messaging the police, finding new friends, having to know our dates, maintaining relationships, chatting with colleagues, messaging our friends about our terrible day, applying for a job, to keeping in touch with our loved ones abroad. It's just part of our society at this point, we have integrated technology into our lives, and it's a fact.</string>
  <string name="about_content_introduction_1">We, as humans are the most social species out there. This is indicated by both the brain structure and also by simply observing what we do throughout our days. Most of the activities we do are social. If we work, we work to be given money by other people and to affect other people. In the meantime, we talk about money and what we do with money with our colleagues. We then spend the money either to appeal to other people (to make a picture of it and put it up online, or to have a shinier car than our neighbor) or to have a good time together with our family or friends. Paying other people in the process, who provide us the services and objects we want.</string>
  <string name="about_content_introduction_2">Communication isn't just verbal and what we consciously choose. In fact, the starting point is nonverbal. The very first way we make sure we're safe and thus understand the world around us when we are little is through our parent's voice and face. There is an undertone to every expression we have, and for a good reason.</string>
  <string name="about_content_introduction_3">We want to be understood and accepted as we are. Texting with someone on a dating app for a week just to be disappointed by how different they are in real life is the last thing you'd like to happen to you. We also want to be affectionate to people we care about. That physical interaction with your partner you miss. The hug that your mom likely deserves. The tickle your siblings deserve. The typical you your friends are so used to meeting and joking around with.</string>
  <string name="about_header_problem">The uh-oh moment</string>
  <string name="about_content_problem">So we communicate online. Efficient, fast, and easy to use, it has a history we can search through, and we can even manage how others see us. Amazing stuff. Now that isn't for free, we are losing some of that underlying tone here.
    \n    One big sign of the shortcomings is online dating. Chat with someone you're romantically interested in for two weeks and you're very likely to be a little surprised when you see them. "It is the same person as on all those social profiles, they seem to dress the same, but there's something different about them". Such experience is not uncommon. One of the reasons why, is because we have different images of the other in our minds, that we construct based on how we see the other. Now, if it is someone you want to like, and perhaps they want you to like them as well (so they send the right emojis, the right messages, photos,...), you are also more likely to form such an image. If you see only happy, well shot images of the person online, more likely than not, this is how you imagine them as well. Another reason is, that the text sent to us doesn't have enough sauce.
    \n    Well, that's not feasible in order to construct the images, so our brain just adds whatever seems most plausible, (often based on our mood) similarly to how AI looks for most plausible combination of words. The thing is, just as AI can hallucinate, so can we.
    \n    So you like editing or removing messages, taking your time editing them, to perfect. Swiping through pages and pages of emojis, while you still circle between the most common 3-5 ones - since those are the "safe bet". Swiping through terabytes of GIFs and Stickers, looking for the funniest, the most expressive ones. But expressive of who? Probably not you, or do you think the waving Forrest Gump is the same as your grandma looking for an interaction with you, so she sent you a GIF of that (or the thousands of puppies and kitties she sends now and then). All aforementioned is explicit, meaning we have to think about every single thing we do within the interaction. Now if we compare it to the nuances we carry with our body movement, speech and facial expressions‚Äîthey are not chosen, it just happens to be the way you express yourself.</string>
  <string name="about_header_solution">The change</string>
  <string name="about_content_solution_0">What we see as a possible way to overcome the current issues is to augment messages with expressions that would be otherwise missing in an abstract way. This doesn't mean an AI would be a middleman and tell you how your friend Steve waved at you. Instead, you are the judge of what a particular expression means. Perhaps Steve is at a meeting and can't fully focus on your messages‚Äîthat is something you would recognize if you saw him, but not in a regular online chat. That's what Augmy combats‚Äîhelping you understand Steve's expressions as they happen.</string>
  <string name="about_content_solution_1">We also believe in user freedom‚Äîyou are the one who expresses and recognizes what certain expressions mean. No third party can do that more accurately than you. Also, we don't believe the dynamic character of communication can be redesigned from the ground up. What improves communication will be used, and what doesn't work doesn't need to be there.</string>
  <string name="video_heider_simmel_url">https://www.youtube.com/watch?v=VTNmLt7QX8E</string>
  <string name="video_heider_simmel_title">Heider and Simmel (1944) animation</string>
  <string name="about_header_demo">Try it out</string>
  <string name="about_content_demo">We are still working hard on this, but expect a live demo where you can compare the different solutions for yourself.</string>
  <string name="about_header_join_us">How can you participate?</string>
  <string name="about_content_join_us_0">We are in search of people interested in enriching communication the same way we do! We are particularly looking for people interested in (cyber)psychology, linguistics, machine learning, and developing with Kotlin or Rust. You can contact us directly at info@augmy.org.</string>
  <string name="about_content_join_us_1">Perhaps you have an amazing new idea we should look into and experiment with. In that case, please, share it with us at info@augmy.org.</string>
  <string name="about_content_join_us_2">We are also researching the effects of our additional functionalities. You can sign up for this in our app and navigate there with https://augmy.org/research-sign-up.</string>
  <string name="about_content_join_us_3">Financial support is always welcomed. While in an ideal world, we could just do the work without having to pay anything, many of the things we do require financing. If this project is something you want to be done, please, consider supporting us here [coming soon!].</string>
  <string name="about_content_join_us_4">Share. Even a single additional person knowing about our work and the vision means a lot to us. So, anyone, who you think would like to communicate meaningfully is someone who may appreciate you sharing this project with them.</string>
  <string name="about_content_join_us_share">Follow and share</string>
  <string name="about_header_roadmap">Roadmap</string>
  <string name="about_content_roadmap">You can see what's currently ahead of us</string>
  <string name="about_content_roadmap_here">here</string>

  <string name="about_business_heading">The future of communication, together.</string>
  <string name="about_business_summary">We help your business to be step ahead in the new era of online communication. Our solutions go beyond offering tools to users and customers‚Äîwe create and facilitate social environments where users enjoy being and can build their social networks with great accuracy.</string>
  <string name="about_business_list_heading">The most common applications for our solutions:</string>
  <string name="about_business_list_0">Prevention and detection of AI content and spam</string>
  <string name="about_business_list_0_content">We create spaces for humans. Robots clearly stand out, so let's weed them out as needed.</string>
  <string name="about_business_list_1">Supercharge of existing communication tools</string>
  <string name="about_business_list_1_content">Be it a specific functionality your users are lacking to grow their relationships, or an algorithm that helps you build your product for them. We provide it.</string>
  <string name="about_business_list_2">Customer support</string>
  <string name="about_business_list_2_content">Meet customers where they are‚Äîlet agents and yourself understand the customer better.</string>
  <string name="about_business_list_3">Sentiment analysis‚Äîbeyond text and emoji inference</string>
  <string name="about_business_list_3_content">We don‚Äôt pretend to do magic out of simple texts. People don‚Äôt communicate only through text anymore, we are offering sentiment analysis with depth no competition can offer.</string>
  <string name="about_business_list_4">Implementation of a chat for users in any app or website</string>
  <string name="about_business_list_4_content">An easy and straightforward way to allow your users to understand each other and stay in touch. Use our full implementation of a chat to save yourself time in development.</string>
  <string name="about_business_list_5">Data quality assurance</string>
  <string name="about_business_list_5_content">We help LLMs understand humanness better. Be it the sarcasm within a prompt, or the enrichment of information that can thereafter used for training, we can help.</string>
  <string name="about_business_footer">Let's get in touch via email or you can schedule a call.</string>
  <string name="about_business_footer_link_0">email</string>
  <string name="about_business_footer_link_0_url">mailto:brand@augmy.org</string>
  <string name="about_business_footer_link_1">schedule a call</string>
  <string name="about_business_footer_link_1_url">https://calendar.app.google/YK5wVD5Eq3n2BQ1L6</string>

  <string name="about_research_summary">Anyone can talk about the theoretical benefits of their work, but very few actively try to disprove their own theories and assumptions to seek the answers to their questions. Not only is our focus to measure and observe how our solutions affect people and subsequent communication, but we also want to contribute to the collective knowledge about computer-mediated communication. In the form of in-house research and providing the right tools for individuals, groups, and organizations that share our collective quest of advancing science and applying the solutions in practice.</string>
  <string name="about_research_platform_heading">Work with us!</string>
  <string name="about_research_platform_preamble">Ecologically valid environment for computer-mediated communication research? Not an easy task without good connections, tough skills, and a lot of time, or enough grant money to develop the required software. That's something we are here to change.
  \n    We are currently working on the Augmy Research Platform, where you can test your ideas and experiment with existing or your own augmentations of the communication interfaces. First, you select the target group, be it desktop, tablet, or mobile users, new or existing. Second, you select what is and what isn‚Äôt present in the app and/or in what way (our app is modular, anything can be modified or removed). Then, users are notified about your research, sign up (and agree to terms), and only the selected information about their use (they were informed about) is sent either to your university‚Äôs server or our servers (with scheduled deletion).
  \n    Your ideas don‚Äôt need to stay only theoretical, waiting to be noticed by developers and product managers. We can put your ideas and solutions into practice together, for users to use, and make a tangible impact right away.</string>

  <string name="about_research_statement_heading">Our mission statement</string>
  <string name="about_research_statement_preamble">Much of the focus in the email communication era was on the lack of social and contextual cues‚Äînot enough information presented (e.g., Media Richness Theory).
  \n    While, arguably, we have the means to express ourselves fully today (with the use of emojis, stickers, and GIFs), it works as long as we decide to do so and are fully aware of our inner state and can express it accurately and in non-ambiguous way (=it represents us 1:1 and the other person can interpret it the same way). This can obviously never be the case, and the explicitness of online communication only raises further issues of impression management, emotional labor, etc.
  \n    Much of the focus today, with the increased consumption of online content, is on the passivity of the observers. However, observing can be seen as a social act within a social context. It, however, becomes a problem as it‚Äôs detached from its social context, and the observer becomes entirely anonymous. Crucially, that happens when the observing does not represent any social behavior and can be at most visualized by an increase in the number of views. This is problematic for both the emitter and the receiver. If cognitive biases show us anything, it‚Äôs that we are better at interpreting naturally and socially meaningful information and struggle with abstract, decontextualized, or anonymized data that lacks interpersonal cues, often leading to misattribution, overgeneralization, or false consensus effects‚Äîultimately distorting how both the emitter and the receiver understand engagement, relevance, and intent. This, among other examples, is in line with the current state of computer-mediated communication (CMC).
  </string>
  <string name="about_research_statement_goals_heading">This is not just a matter of adaptability. It is also a matter of design. Which is the reason for our movement‚ÄîAugmy. Our goals for the design are as follows:</string>
  <string name="about_research_statement_goals_0">Anonymity</string>
  <string name="about_research_statement_goals_0_content">We believe that anonymity can be largely explained by the ambiguousness and lack of personal depth of expressions (e.g., differentiation of person(ality) from content, multimodal congruence). Thus, the goal is to bring subjective ‚Äúcharacter tone‚Äù to each expression or set of expressions. In practice, a person related to the sender can differentiate between ‚ÄúI‚Äôm okay‚Äù sent by the related sender and ‚ÄúI‚Äôm okay‚Äù from an unrelated sender.</string>
  <string name="about_research_statement_goals_1">Intuitiveness, expression</string>
  <string name="about_research_statement_goals_1_content">In expression, the problem is that an individual communicates via a tool and sees it as such; everything has to be effortfully, explicitly defined and pre-processed into a condensed, rigid form. It is equivalent to having emotional facial paresis, where we can‚Äôt spontaneously react to, for example, a joke, but can move facial muscles voluntarily. Our devices are extensions of our bodies and should act as such in communication. Our digital representation of us is as complex and important as the physical representation. The goal, thus, is to make it intuitive to express one‚Äôs inner state and thoughts.</string>
  <string name="about_research_statement_goals_2">Intuitiveness, comprehension</string>
  <string name="about_research_statement_goals_2_content">Our attention is selective, meaning that at different times, different things may interest us and be beneficial for understanding the context and message delivered to us. This works great in real life. In CMC, however, the majority is presented linearly and is designed as a book to be read. Thus, in CMC, it‚Äôs a synchronous message delivered asynchronously, which can be read at any time. In real life, it is an asynchronous message (different messages and cues at the same time) delivered synchronously. This can work for various, mostly formal settings. The problem is, we are beyond using CMC as an occasional tool. In many cases, CMC replaces real-life interactions and acts as the primary means of communication. Our goal is, then, to have a design that widens the communication channel asynchronicity in a way that people can benefit from having selective attention and increase (at the very least the feeling of) mode delivery synchronicity. All this while balancing cognitive and sensory load and maintaining ease of use.</string>

  <string name="about_research_introduction_heading">Introduction</string>
  <string name="about_research_introduction_content">Communication online is more prevalent than ever, with the global user base growing exponentially each year. Notably, the most used communication application WhatsApp nearing 25% of the world's population [1, 2]. Not only can communication online be exclusively preferred (particularly among younger users) [3, 4], but it may be the only option for communication at certain periods, such as while people are apart at work, on public transport, or during prolonged periods, such as during quarantine.
    \n    While the use of additional modalities to text online communication is becoming a more common way of expression (such as the video format of TikTok, Instagram reels, and Youtube shorts) and their use is increasingly growing, text-based communication (particularly instant messaging) is still used predominantly for communication in one-to-one. One of the likely reasons is its advantage in privacy, as IM allows for more control, which is especially desired by users in cases when impression management plays a key role (e.g., dating applications, social anxiety, ASD). It can also be considered easier to use, as IM allows for asynchronous communication and doesn't require a high degree of technical knowledge. Its simplicity often leads to more direct exchanges, as messages are typically straightforward. However, issues arising due to the ambiguousness in meaning and understanding are still very common even when users are provided with functionalities that allow for enriching texts further (e.g., images, GIFs, stickers, emojis/emoticons).
    \n    We argue, that while additional cues are gradually being embedded into the commonly used social media software (e.g., online status, typing indicator), they are still not sufficient as expressive means of emotions, affect, state, and intention. Currently, the majority of information between people is explicitly chosen by the senders. This can not only cognitively overwhelm users, but it also may lead to overuse of impression management. To solve these issues, communication online could provide abstracted implicit expressions, contextual information, and interpersonal synchrony.</string>
  <string name="about_research_content_heading">Content</string>
  <string name="about_research_content_content_0">We focus primarily on text-based communication, but many of the outcomes of our work are applicable and will apply to other communication modalities (outside of the scope of this project for now).
    This section will explain our approach to solving the aforementioned issues, namely, the lack of implicit expressiveness, ambiguousness, cues, and synchrony.
    \n    In the context of communication, expressiveness is a very specific way of an individual explaining (both consciously and unconsciously) their current inner state and intentions. The contents are also altered by the current context of the situation, the environment in which it happens, affection, and the emotional state of the individual before, during, and after the matter.
    \n    Clearly, this is something connected to spontaneous bodily functions (e.g., breathing rate, heart rate, skin conductance, tone of voice, sweating, spontaneous facial expressions, and eye movement) that are usually not directly embedded in text messages. It can be relatively easily attached to messages, and/or shared between users (such as heart rate per minute) with the use of many sensors available in both smartphones and smartwatches, its presence however may cause cognitive overload [5, 8], likely due to difficulty with its interpretation.
    \n\n    By implicitness, we refer to the degree of attention given by the individual expressing themselves to individual cues being transmitted. In other words, it is the "flow" or fluency with which the individual focuses solely on expressing themselves without giving a second thought to the way they express it. The less thought given to the means of expression, the more "natural" such expression usually is.
    \n    Someone accustomed to the expressiveness of emojis will likely choose such means of enriching communication over others, especially in times of elevated emotional states, such as sadness or anger, where people tend to lean toward the more "automatic" action. Additionally, an implicit message is a message with further meaning embedded within the message outside of the plain content. Specifically in the context of communication online, this can be for example the speed with which an individual types or responds.
    \n    This implies variability in individuals. Both in preference and the degree of habituation of the given channel of expression. How the individual sees themselves and the particular cues transmitted affect the expressions. For example, an Italian may be very expressive in his body movements while expressing himself, but with a mirror pointed at him, he may start observing the ways he expresses himself and manage the impressions others may have of him. Similarly, if the Italian person mentioned would be talking to someone blind and had to mention all the movements he would usually do, it may affect the way he expresses himself.
    \n\n    Ambiguity is in the context of communication online an expression lacking clarity or a heightened possibility of the expression being misinterpreted (interpreted in a different way than the sender intended) by either party.
    \n    Certain added cues can already disambiguate messages, such as emojis [6, 7]. Additional accurate cues that are both specific to a message and the context in which it was sent, and implicitly expressed by an individual may provide the right toolset to understand expressions correctly [9]. Humans are naturally looking for patterns in everything. Its accuracy although depends on a) the way information is presented b) the amount of information available c) the preference of the individual for such information, and d) contextual information; among others. Ambiguity arises not due to messages being not clear enough, but because humans fail in the interpretation of the information available to them. The right combination of modalities combined with representative visualization, together with the original explicit content itself may greatly improve the accuracy of interpretation.
    \n    Another very relevant issue we strive to combat is the lack of synchrony, in other words, facilitate synchrony. While communication online had been notoriously known to be asynchronous in the past, more recently, it has the option of near synchrony when both persons are getting continuous feedback on the other typing and interactions happening in real-time. Thus, we define synchrony in this context as not mere time-related connection, but rather as interpersonal synchronization via various interconnected feedback loops. This requires many cues to be transmitted in real-time and to be reflective of the person's interactions with the device or of their body. Such synchrony is similar to more subtle ways of unconscious mirroring. For example synchrony in breathing rate, heart rate, speed of talking, facial expressions, and vocal synchronization among others [10].
    \n\n    How we initially envisioned the realization of these concepts was via abstract patterns of expressions. Similar to how the Heider-Simmel illusion is a means of telling a story without anything explicitly being told.</string>
  <string name="about_research_content_content_1">    This "quasi-nonverbal" communication can be widely seen in video games where real-time user input is reflected in the characters or objects they control. This means using high abstraction (from raw information, such as heartbeat) cues, that are communicated subtly, directly from not sender's input, but from the way the sender provides the input (the way he types, the way he handles his device, moves his mouse, etc.).
    \n    Such types of simple sequences of expressions are relatively easy to interpret for the receiver and can act as a background for messages telling a story. The key here is the cognitive load it creates for an individual, as an overly animated or "rich" message can distract, cause misinterpretation as a whole, and be difficult to interpret at once.
    \n    Our approach will be applied to production (widely public) applications for smartphones, desktops, and smartwatches. Variability in each device is what makes this an even more interesting endeavor as users using different devices can communicate with each other at the same time. Client API and Interpreter API are what can make the communication not only implicitly expressive but also explainable both for users and researchers (e.g., for multigenerational or multicultural communication).
    \n    The solutions developed by us can be variously applied to different pieces of software. Among widely used chatting applications, forums, comment sections, live chats, and others, the rising occurrence of online therapies may especially require facilitation in communication, as within therapies online, the communication isn't as expressive as may be needed, harming the connection between the client and a therapist. Also, it may take longer to interact, as one thinks more before sending what he typed, and waits for the response to get validated.</string>
  <string name="about_research_prospects_heading">Research prospects</string>
  <string name="about_research_prospects_content">While many researchers attempted implementing prototypes with additional cues, context, and implicity, such a strategy requires a lot of initial time investment for the prototype to be developed [11], and few of such prototypes can be reused and are rarely maintained. Notably, the prototypes lack the functionalities most used applications on the market commonly have (e.g., sending files, images, videos, GIFs, stickers, emojis, and audio recordings).
    \n    One of the more nuanced outcomes of our work will be the common use of new communication modalities within user-oriented applications and new ways for users to express themselves and, thus, interpret and understand each other. This creates new opportunities for us, and other researchers to study the different patterns in expressions of users, and also to attempt to map them onto underlying innate functions of expression and interpretation.
    \n    Our goal is to continuously implement experimental (not common to IMs) ways of adding cues and implicit expressiveness since this is something research indicates to be helpful. The main difference is that our applications are directed at users, not research subjects, which can be beneficial for ecological validity, yet reduces the options provided for our research if we are not to interrupt users. Yet, we think a middle ground can be found. Thus, we are working on an environment shared by users and researchers to conduct within-application studies.
    \n    The whole design of the applications is modular, and each functionality is a module that can be either included or excluded, depending on the current settings either globally or specific to a user. Each functionality will be thus tested in an environment that includes functionality common to other applications and their impacts on communication can be directly compared. Due to our user-centered approach, each functionality will still have rounds of testing and tweaking, focusing on qualitative results before it's released globally to all users outside of exceptions (such as users in ongoing research).
    \n    The outcomes of the continuous research can be both qualitative and quantitative. Qualitative outcomes will be collected with explicit knowledge of the users, who can review what is being sent for the research before it's sent and can remove it at any time. This includes questionnaires, content of messages, and any other cues both common in regular instant messaging applications, and the added cues specific to our application. Quantitative outcomes are more generalized information collected and clustered into various categories (e.g., culture, city, country, age). Such information is crucial when a researcher attempts to evaluate trends within certain social groups, global communication in general, or specific channels used and their effects on the communication, or the persons using it.
    \n    The environment is experimental, meaning researchers can file new research based on their specific needs via our custom-built research interface and directly impact the behavior of the application for specific users. Including sampling options, functionalities that will be included or functionalities that will be excluded, chatting outcomes expected (thus, what data will be stored), and the period during which research will be conducted. Access to the research interface can be provided to any researcher who is interested in such research.
    \n    It is important to note, that none of the quantitative information is directly accessible by the researcher as the information stored for research is disconnected from the instant messaging database. Neither is the information directly identifiable by legal name, username, exact address, device identifier, or database record identifiers.</string>
  <string name="about_research_options_heading">Options for other researchers</string>
  <string name="about_research_options_content">The works of our team can be re-used not as a prototype as a whole, but into existing projects and prototypes as an SDK (Software Development Kit), which can be implemented into any applications targeting Android, iOS, macOS, Windows, Linux, or Web. It is a bundle of functionalities that can be split into even smaller bundles for specific uses. Such SDKs take advantage of any input available.
    \n    In terms of smartphones, many of the available sensors can be used for interpretation. And while desktop devices lack the number of sensors and thus the ease of interpretation, they can have similarly rich real-time information, such as movements of the mouse, or typing variability.
    \n    Another component that can benefit both commercial and non-commercial projects and applications is an API (Application Programming Interface). Toolset with mostly logic for evaluation, transmission of key information between devices, and other technical aspects of communication online. It is tightly connected to our Interpreter, which builds on both common contents (e.g., text, emojis, reactions, typing time, read/seen), the added cues via additional functionalities, and the context in which it happens. This provides it with a unique insight into interpersonal communication. The outcomes of the Interpreter are then used to further validate and improve the interactions, and to add a layer of understanding for collected study data (such as emoji preference before and after intervention).
    \n    The API also includes a statistical section, which can be used by any third party (e.g., governmental bodies, researchers, statistical tools, intervention developers) for interpretation of the communication online in general.</string>
  <string name="about_research_bibliography_heading">Bibliography</string>
  <string name="about_research_bibliography_content">
    \n1. Two Billion Users ‚Äî Connecting the World Privately. (2020, February 12). About Facebook. https://about.fb.com/news/2020/02/two-billion-users/
    \n2. Statista. (2023). Most popular messaging apps 2023 | Statista. Statista; Statista. https://www.statista.com/statistics/258749/most-popular-global-mobile-messenger-apps/
    \n3. Karapetyan, A., &amp; Gardner, S. (2023). The Online and Offline Communication Preferences of Armenian Social Network Users. Journal of Sociology: Bulletin of Yerevan University, 14(2 (38)), 66‚Äì80. https://doi.org/10.46991/BYSU:F/2023.14.2.066
    \n4. Chung, J. E. (2013). Social interaction in online support groups: Preference for online social interaction over offline social interaction. Computers in Human Behavior, 29(4), 1408‚Äì1414. https://doi.org/10.1016/j.chb.2013.01.019
    \n5. Aidi, X. (2009). Cognitive Overload and Its Countermeasures from the Angle of Information Processing. 2009 Third International Symposium on Intelligent Information Technology Application. https://doi.org/10.1109/iita.2009.278
    \n6. Cui, J., Colston, H. L., &amp; Jiang, G. (2024). Is That a Genuine Smile? Emoji-Based Sarcasm Interpretation Across the Lifespan. Metaphor and Symbol, 39(3), 195‚Äì216. https://doi.org/10.1080/10926488.2024.2314595
    \n7. Chauhan, D. S., Singh, G. V., Arora, A., Ekbal, A., &amp; Bhattacharyya, P. (2022). An emoji-aware multitask framework for multimodal sarcasm detection. Knowledge-Based Systems, 257, 109924. https://doi.org/10.1016/j.knosys.2022.109924
    \n8. Tran, J., Nguyen, Q. V., Hol, A., &amp; Simoff, S. (2019). Reduction of Cognitive Overload in Online Reviews Using Data Visualisation. Proceedings of the Australasian Computer Science Week Multiconference. https://doi.org/10.1145/3290688.3290708
    \n9. Boutet, I., Guay, J., Chamberland, J., Cousineau, D., &amp; Collin, C. (2022). Emojis that work! Incorporating visual cues from facial expressions in emojis can reduce ambiguous interpretations. Computers in Human Behavior Reports, 100251. https://doi.org/10.1016/j.chbr.2022.100251
    \n10. Rinott, M., &amp; Tractinsky, N. (2021). Designing for interpersonal motor synchronization. Human‚ÄìComputer Interaction, 1‚Äì48. https://doi.org/10.1080/07370024.2021.1912608
    \n11. Buschek, D., Hassib, M., &amp; Alt, F. (2018). Personal Mobile Messaging in Context. ACM Transactions on Computer-Human Interaction, 25(4), 1‚Äì33. https://doi.org/10.1145/3201404
  </string>

  <string name="roadmap_heading">Roadmap</string>
  <string name="roadmap_last_update">Last updated: 8th January 2025</string>
  <string name="roadmap_description">The estimated timeline for this project. Note that anything on this page is subject to change considering the current stage of the development.</string>
  <string name="roadmap_expand_button">Details</string>

  <string name="roadmap_0_title">Social networking support, 1Q 2025</string>
  <string name="roadmap_0_description">This includes users having the ability to personalize their networks within the application and modify it at any time.</string>
  <string name="roadmap_1_title">Chatting support, 2Q 2025</string>
  <string name="roadmap_1_description">Ability to chat with anyone within the user's network, both in real-time and asynchronously.</string>
  <string name="roadmap_2_title">First experimental functionality 3Q 2025</string>
  <string name="roadmap_2_description">The first experimental functionality is developed and implemented into chatting. The functionality aims to improve expressiveness, and implicity via additional communication cues within interactions and is part of a planned bundle of functionalities we will gradually add.</string>
  <string name="roadmap_3_title">First research, 4Q 2025</string>
  <string name="roadmap_3_description">The first functionality(ies) will be compared to a control group. The research will be conducted to find nuances from its implementation and use. The article will be published in any relevant journal.</string>
  <string name="roadmap_4_title">An initial version of the research interface, 4Q 2025 - 1Q 2026</string>
  <string name="roadmap_4_description">A custom interface allowing for automatic collection and sampling of research, embedded into our product suite. While not widely advertised for researchers, the internal use of the research interface can begin.</string>
  <string name="roadmap_5_title">SDK public release, 1Q 2026 onwards</string>
  <string name="roadmap_5_description">Bundles that are implementable to any existing popular application are being released publicly. Any existing or new application can use our existing logic and improve the quality of communication. The range of functionalities implemented is increasing. The more impactful functionalities are being prioritized and gradually integrated into our application and the SDK bundles.</string>
  <string name="roadmap_6_title">An initial version of Interpreter</string>
  <string name="roadmap_6_description">Even with a minimal user base, our works on Interpreter can be put into practice and directed towards solutions developed within our application, SDK bundles, and research interface.</string>
  <string name="roadmap_7_title">Full functionality support, Q4 2026</string>
  <string name="roadmap_7_description">Our application supports functionality most common to popular instant messaging applications. This provides us with the ability to directly compare the effects of the additional functionalities and modifications we applied so far in contrast to traditional forms of communication.</string>
  <string name="roadmap_8_title">A production version, Q1 2027</string>
  <string name="roadmap_8_description">Our application is ready to be widely published and used by any user who wants to improve the quality of their communication online.</string>

  <string name="delete_me_heading">Data deletion</string>
  <string name="delete_me_description">Are you looking to delete data associated with you? This is the right place. You can either request for a full deletion or just a partial.
    \nFor example, you may want to delete only messages associated with you, your social circle associations, or research data connected to you.
    \nHowever, please note that we delete based on the type of data rather than specific pieces of data. For example, all your messages may be deleted, not just one message.</string>

  <string name="delete_me_user_uid_label">User UID</string>
  <string name="delete_me_user_id_hint">NABWwZun4QPIxYInouchx0dVB8g1</string>
  <string name="delete_me_contents_label">What would you like us to delete?</string>
  <string name="delete_me_contents_hint">All of the cookies</string>
  <string name="delete_me_reason_short_0">It's difficult to understand messages</string>
  <string name="delete_me_reason_short_1">I spend too much time here</string>
  <string name="delete_me_reason_short_2">I don't understand how to use Augmy</string>
  <string name="delete_me_reason_short_3">I use a different account now</string>
  <string name="delete_me_reason_short_4">I prefer regular messaging apps</string>
  <string name="delete_me_reason_short_5">Other</string>
  <string name="delete_me_reason_long_label">Please, explain further if possible</string>
  <string name="delete_me_reason_long_hint">You offer too many cookies but I'm on a diet...</string>
  <string name="delete_me_button_send">Send as an email</string>

  <string name="accessibility_about_poster">Poster employing people to join the project as team members.</string>
  <string name="accessibility_light_mode">Light mode</string>
  <string name="accessibility_logo">Logo containing a puffer fish in a defensive state</string>
  <string name="accessibility_dark_mode">Dark mode</string>
  <string name="accessibility_menu">Open side menu</string>
  <string name="accessibility_play_video">Play video</string>
  <string name="accessibility_button_expand">Expand</string>
</resources>