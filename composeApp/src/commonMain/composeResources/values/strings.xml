<resources>
  <string name="app_name">Augmy Interactive</string>

  <string name="website_footer">© %1$d Augmy Interactive</string>

  <string name="landing_header_heading">Implicit, expressive, and embedded</string>
  <string name="landing_header_content">That's the new era of communication online.</string>

  <string name="landing_block_0_heading">Express yourself without missing a beat</string>
  <string name="landing_block_0_content">Be closer to people you want to be close to. Because that is something everyone deserves. Make yourself more understood through expressive messages that reflect your emotional state, not just words.</string>

  <string name="landing_block_1_heading">Communicate instinctively and with ease</string>
  <string name="landing_block_1_content">Our goal is to make communication authentically implicit again. You won’t have to ponder which emoji best expresses your emotions; you’ll simply be understood.</string>

  <string name="landing_block_2_heading">Everyone wants to be understood, let’s start with you</string>
  <string name="landing_block_2_content">Sometimes, expressing yourself can be challenging, and there are moments when you may lack the energy to explain. That's why we're dedicated to helping you be understood.</string>

  <string name="landing_footer_heading">Communication matters</string>
  <string name="landing_footer_content">If you want to understand someone better — or help them understand you — we’re here to help, whether it’s your partner, a friend, or even your grandma who struggles with emojis.</string>

  <string name="landing_download_button">Download</string>
  <string name="landing_download_not_distributed">You can't register to open beta quite yet. Follow us on social media sites and we'll make sure you know about it, once it's ready.</string>


  <string name="toolbar_action_about">About</string>
  <string name="toolbar_action_about_research">Research</string>
  <string name="toolbar_action_about_business">Business</string>
  <string name="toolbar_action_contacts">Contacts</string>

  <string name="contacts_workplace">Workplace</string>
  <string name="contacts_workplace_value">Prague, Czechia</string>
  <string name="contacts_email">Email</string>
  <string name="contacts_email_value">info@augmy.org</string>
  <string name="contacts_twitter">https://www.twitter.com/AugmyInteractiv</string>
  <string name="contacts_instagram">https://www.instagram.com/augmy_interactive</string>
  <string name="contacts_linkedin">https://www.linkedin.com/company/augmy-interactive</string>
  <string name="contacts_twitter_tag">@AugmyInteractiv</string>
  <string name="contacts_instagram_tag">@augmy_interactive</string>
  <string name="contacts_linkedin_tag">@augmy-interactive</string>

  <string name="about_content">Are you interest in what we do? Let us explain.</string>
  <string name="about_header_summary">Summary</string>
  <string name="about_content_summary">We are incredibly social beings, we like to communicate and interact with others, no matter the reason. Nowadays, this seems to happen online, particularly via instant messaging apps, forums like Reddit, or comment sections. Communicating online is relatively easy and efficient, yet it doesn't seem to be us communicating, but the online versions of us - it's the GIFs, Stickers, avatars, letters, sentences, and emojis. It may also be pretty exhausting and problematic that we decide every single thing about the interactions and how we are represented online. We should be understood, without the hustle of finding the ways to communicate it.</string>
  <string name="about_header_introduction">Why is this important? (Introduction)</string>
  <string name="about_content_introduction_0">Nearly every fourth person uses WhatsApp alone. Communication online is more relevant than ever, and we are getting in line with that. From online therapy, governmental inquiries, messaging companies via live chats, finding new friends, having dates on applications, maintaining relationships, chatting with colleagues, finding the right coffee shop, and deciding on the best vacuum cleaner, and a phone case that will protect our "precious", among others. It's just part of our society at this point, we have integrated technology into our lives, and it's a fact.</string>
  <string name="about_content_introduction_1">We, as humans are the most social species out there. This is indicated by both the brain structure and also by simply observing what we do throughout our days. Most of the activities we do are social. If we work, we work to be given money by other people and to affect other people. In the meantime, we talk about money and what we do with money with our colleagues, who seem to be in a similar position. We then spend the money either to appeal to other people (to make a picture of it and put it up online, or to have a shinier car than our neighbor) or to have a good time together with our family or friends. Paying other people in the process, who provide us the services and objects we want.</string>
  <string name="about_content_introduction_2">Communication isn't just verbal though! In fact, the starting point is nonverbal. The very first way we make sure we're safe and thus understand the world around us when we are little is through our caregiver's vocal and facial expressions. There is an underlying undertone to every expression we have, and there is a good reason for that. Importantly, we don't even think about it most of the time.</string>
  <string name="about_content_introduction_3">We want to be understood and accepted as we are. Texting someone on a dating app for a week just for them to be disappointed by how different we are is the last thing you'd like to happen to you. We also want to be affectionate to people we care about. That physical interaction with your partner you miss. The hug that your mom likely deserves. The tickle your siblings deserve. The typical you your friends are so used to meeting and making fun of.</string>
  <string name="about_header_problem">The uh-oh moment (Problem statement)</string>
  <string name="about_content_problem">So we communicate online. Efficient, fast, and easy to use, it has a history we can search through, and we can even manage how others see us. Amazing stuff. Now that isn't for free, we are losing some of that underlying tone here.
    \n    One of such big red flags is online dating. Chat with someone you're romantically interested in for two weeks and you're very likely to be a little surprised when you see them. "It is the same person as on all those social profiles, they seem to dress the same, but there's something different about them". Such experience is not uncommon. One of the reasons why, is because we have different "social profiles" (images of the other) in our minds. Now if it is someone you want to like, they want you to like (so they send the right emojis, the right messages, etc.), then you are also likely to form such an image. If you see happy, perfect images online from the person, more likely than not, this is how you imagine them to be most of the time. Another reason is, the text being sent to us doesn't have much sauce.
    \n    Well, no problem, we just add it afterward, ourselves, based on our mood, based on how we think they perceive us or how we want them to perceive us.
    \n    So you like editing or removing messages, taking your time editing them, to perfect. Swiping through pages and pages of emojis, while you still circle between the most common 3-5 ones - those are the ones everyone understands, it's a safe bet. Swiping through terabytes of GIFs and Stickers, looking for the funniest, the most expressive ones. Oh! Expressive you said? Expressive of who? Certainly not the sender, I don't think the waving Forrest Gump is the same as your grandma looking for an interaction with you (or the thousands of puppies and kitties she sends now and then). All aforementioned is explicit, meaning we have to think about every single thing we do within the interaction. Now if you compare it to the mentioned ways communication isn't just verbal, the nonverbal is predominantly implicit - not chosen to happen by choice, it just happens to be. Now this seems like a serious problem.</string>
  <string name="about_header_solution">Time for a change (Solution)</string>
  <string name="about_content_solution_0">In our opinion, the lack of implicitness and expression can be solved by adding more raw unedited information that expresses you to the interactions. However, we acknowledge there are both privacy issues and the undesirability of such a solution. Thus, another requirement of the solution is that it shouldn't expose and undercut you, instead, it should add a new value and stay at the level you are - abstract. When you read this text, it is abstract. It invokes something in you, you imagine it, analyze it, and viola a meaning! Similar to emojis, and capital letters, any other object can express sound, smell, movement, or color. A great example of this is Heider-Simmel animation.</string>
  <string name="about_content_solution_1">\n    We all know it's just a bunch of simple objects, recorded just as simply. Yet there is a story behind all of the otherwise random movements.
    \n    What we strive to do and how to solve this is thus threefold: implicit, expressive, and embedded. This goes hand in hand with user-centered design. We don't want people to be overwhelmed by the amount of information, we don't want to go against the choices users usually have, nor do we want people to have to explain themselves all the time. "What did you mean by this emoji?", "Why didn't you use emoji here and there?"</string>
  <string name="video_heider_simmel_url">https://www.youtube.com/watch?v=VTNmLt7QX8E</string>
  <string name="video_heider_simmel_title">Heider and Simmel (1944) animation</string>
  <string name="about_header_demo">Try it out</string>
  <string name="about_content_demo">We are still working hard on this, but expect soon to try out the new ways of communication online right here, at any time!</string>
  <string name="about_header_join_us">How can you participate?</string>
  <string name="about_content_join_us_0">We are in search of people interested in enriching communication the same way we do! We are particularly looking for people interested in (cyber)psychology, linguistics, machine learning, and developing with Kotlin or Rust. You can contact us directly at info@augmy.org.</string>
  <string name="about_content_join_us_1">Perhaps you have an amazing new idea we should look into and experiment with. In that case, please, feel free to contact us at info@augmy.org.</string>
  <string name="about_content_join_us_2">We are also researching the effects of the additional cues and contexts. You can sign up for research here [coming soon!].</string>
  <string name="about_content_join_us_3">Financial support is always welcomed. While in an ideal world, we could just do the work without having to pay anything, many of the things we do require financing. If this project is something you want to be done, please, consider supporting us here [coming soon!].</string>
  <string name="about_content_join_us_4">Share. Even a single additional person knowing about our vision and our work means a lot to us. So, anyone, who you think would like to communicate meaningfully is someone who may appreciate you sharing this project with them.</string>
  <string name="about_content_join_us_share">Follow and share</string>
  <string name="about_header_roadmap">Roadmap</string>
  <string name="about_content_roadmap">You can see what's currently ahead of us</string>
  <string name="about_content_roadmap_here">here</string>

  <string name="about_business_content">We are actively looking for organizations and teams interested in working with us and helping us achieve the goals we set to achieve. Notably psychological supervision both for development and research.
    \nIf you're open to working with us, please, contact us at brand@augmy.org.</string>

  <string name="about_research_content">This page assumes that the audience possesses a foundational understanding of scientific concepts and is interested in the motivations and hypotheses underlying this project. Our goal is to inspire researchers by highlighting the potential outcomes of this initiative—not only for users communicating through the tools developed by our team but also for researchers leveraging these resources. We are dedicated to validating our proposed hypotheses and exploring innovative ways to enrich communication for both researchers and intervention developers.</string>
  <string name="about_research_introduction_heading">Introduction</string>
  <string name="about_research_introduction_content">Communication online is more prevalent than ever, with the global user base growing exponentially each year. Notably, the most used communication application WhatsApp nearing 25% of the world's population [1, 2]. Not only can communication online be exclusively preferred (particularly among younger users) [3, 4], but it may be the only option for communication at certain periods, such as while people are apart at work, on public transport, or during prolonged periods, such as during quarantine.
    \n    While the use of additional modalities to text online communication is becoming a more common way of expression (such as the video format of TikTok, Instagram reels, and Youtube shorts) and their use is increasingly growing, text-based communication (particularly instant messaging) is still used predominantly for communication in one-to-one. One of the likely reasons is its advantage in privacy, as IM allows for more control, which is especially desired by users in cases when impression management plays a key role (e.g., dating applications, social anxiety, ASD). It can also be considered easier to use, as IM allows for asynchronous communication and doesn't require a high degree of technical knowledge. Its simplicity often leads to more direct exchanges, as messages are typically straightforward. However, issues arising due to the ambiguousness in meaning and understanding are still very common even when users are provided with functionalities that allow for enriching texts further (e.g., images, GIFs, stickers, emojis/emoticons).
    \n    We argue, that while additional cues are gradually being embedded into the commonly used social media software (e.g., online status, typing indicator), they are still not sufficient as expressive means of emotions, affect, state, and intention. Currently, the majority of information between people is explicitly chosen by the senders. This can not only cognitively overwhelm users, but it also may lead to overuse of impression management. To solve these issues, communication online could provide abstracted implicit expressions, contextual information, and interpersonal synchrony.</string>
  <string name="about_research_content_heading">Content</string>
  <string name="about_research_content_content_0">We focus primarily on text-based communication, but many of the outcomes of our work are applicable and will apply to other communication modalities (outside of the scope of this project for now).
    This section will explain our approach to solving the aforementioned issues, namely, the lack of implicit expressiveness, ambiguousness, cues, and synchrony.
    \n    In the context of communication, expressiveness is a very specific way of an individual explaining (both consciously and unconsciously) their current inner state and intentions. The contents are also altered by the current context of the situation, the environment in which it happens, affection, and the emotional state of the individual before, during, and after the matter.
    \n    Clearly, this is something connected to spontaneous bodily functions (e.g., breathing rate, heart rate, skin conductance, tone of voice, sweating, spontaneous facial expressions, and eye movement) that are usually not directly embedded in text messages. It can be relatively easily attached to messages, and/or shared between users (such as heart rate per minute) with the use of many sensors available in both smartphones and smartwatches, its presence however may cause cognitive overload [5, 8], likely due to difficulty with its interpretation.
    \n\n    By implicitness, we refer to the degree of attention given by the individual expressing themselves to individual cues being transmitted. In other words, it is the "flow" or fluency with which the individual focuses solely on expressing themselves without giving a second thought to the way they express it. The less thought given to the means of expression, the more "natural" such expression usually is.
    \n    Someone accustomed to the expressiveness of emojis will likely choose such means of enriching communication over others, especially in times of elevated emotional states, such as sadness or anger, where people tend to lean toward the more "automatic" action. Additionally, an implicit message is a message with further meaning embedded within the message outside of the plain content. Specifically in the context of communication online, this can be for example the speed with which an individual types or responds.
    \n    This implies variability in individuals. Both in preference and the degree of habituation of the given channel of expression. How the individual sees themselves and the particular cues transmitted affect the expressions. For example, an Italian may be very expressive in his body movements while expressing himself, but with a mirror pointed at him, he may start observing the ways he expresses himself and manage the impressions others may have of him. Similarly, if the Italian person mentioned would be talking to someone blind and had to mention all the movements he would usually do, it may affect the way he expresses himself.
    \n\n    Ambiguity is in the context of communication online an expression lacking clarity or a heightened possibility of the expression being misinterpreted (interpreted in a different way than the sender intended) by either party.
    \n    Certain added cues can already disambiguate messages, such as emojis [6, 7]. Additional accurate cues that are both specific to a message and the context in which it was sent, and implicitly expressed by an individual may provide the right toolset to understand expressions correctly [9]. Humans are naturally looking for patterns in everything. Its accuracy although depends on a) the way information is presented b) the amount of information available c) the preference of the individual for such information, and d) contextual information; among others. Ambiguity arises not due to messages being not clear enough, but because humans fail in the interpretation of the information available to them. The right combination of modalities combined with representative visualization, together with the original explicit content itself may greatly improve the accuracy of interpretation.
    \n    Another very relevant issue we strive to combat is the lack of synchrony, in other words, facilitate synchrony. While communication online had been notoriously known to be asynchronous in the past, more recently, it has the option of near synchrony when both persons are getting continuous feedback on the other typing and interactions happening in real-time. Thus, we define synchrony in this context as not mere time-related connection, but rather as interpersonal synchronization via various interconnected feedback loops. This requires many cues to be transmitted in real-time and to be reflective of the person's interactions with the device or of their body. Such synchrony is similar to more subtle ways of unconscious mirroring. For example synchrony in breathing rate, heart rate, speed of talking, facial expressions, and vocal synchronization among others [10].
    \n\n    How we initially envisioned the realization of these concepts was via abstract patterns of expressions. Similar to how the Heider-Simmel illusion is a means of telling a story without anything explicitly being told.</string>
  <string name="about_research_content_content_1">    This "quasi-nonverbal" communication can be widely seen in video games where real-time user input is reflected in the characters or objects they control. This means using high abstraction (from raw information, such as heartbeat) cues, that are communicated subtly, directly from not sender's input, but from the way the sender provides the input (the way he types, the way he handles his device, moves his mouse, etc.).
    \n    Such types of simple sequences of expressions are relatively easy to interpret for the receiver and can act as a background for messages telling a story. The key here is the cognitive load it creates for an individual, as an overly animated or "rich" message can distract, cause misinterpretation as a whole, and be difficult to interpret at once.
    \n    Our approach will be applied to production (widely public) applications for smartphones, desktops, and smartwatches. Variability in each device is what makes this an even more interesting endeavor as users using different devices can communicate with each other at the same time. Client API and Interpreter API are what can make the communication not only implicitly expressive but also explainable both for users and researchers (e.g., for multigenerational or multicultural communication).
    \n    The solutions developed by us can be variously applied to different pieces of software. Among widely used chatting applications, forums, comment sections, live chats, and others, the rising occurrence of online therapies may especially require facilitation in communication, as within therapies online, the communication isn't as expressive as may be needed, harming the connection between the client and a therapist. Also, it may take longer to interact, as one thinks more before sending what he typed, and waits for the response to get validated.</string>
  <string name="about_research_prospects_heading">Research prospects</string>
  <string name="about_research_prospects_content">While many researchers attempted implementing prototypes with additional cues, context, and implicity, such a strategy requires a lot of initial time investment for the prototype to be developed [11], and few of such prototypes can be reused and are rarely maintained. Notably, the prototypes lack the functionalities most used applications on the market commonly have (e.g., sending files, images, videos, GIFs, stickers, emojis, and audio recordings).
    \n    One of the more nuanced outcomes of our work will be the common use of new communication modalities within user-oriented applications and new ways for users to express themselves and, thus, interpret and understand each other. This creates new opportunities for us, and other researchers to study the different patterns in expressions of users, and also to attempt to map them onto underlying innate functions of expression and interpretation.
    \n    Our goal is to continuously implement experimental (not common to IMs) ways of adding cues and implicit expressiveness since this is something research indicates to be helpful. The main difference is that our applications are directed at users, not research subjects, which can be beneficial for ecological validity, yet reduces the options provided for our research if we are not to interrupt users. Yet, we think a middle ground can be found. Thus, we are working on an environment shared by users and researchers to conduct within-application studies.
    \n    The whole design of the applications is modular, and each functionality is a module that can be either included or excluded, depending on the current settings either globally or specific to a user. Each functionality will be thus tested in an environment that includes functionality common to other applications and their impacts on communication can be directly compared. Due to our user-centered approach, each functionality will still have rounds of testing and tweaking, focusing on qualitative results before it's released globally to all users outside of exceptions (such as users in ongoing research).
    \n    The outcomes of the continuous research can be both qualitative and quantitative. Qualitative outcomes will be collected with explicit knowledge of the users, who can review what is being sent for the research before it's sent and can remove it at any time. This includes questionnaires, content of messages, and any other cues both common in regular instant messaging applications, and the added cues specific to our application. Quantitative outcomes are more generalized information collected and clustered into various categories (e.g., culture, city, country, age). Such information is crucial when a researcher attempts to evaluate trends within certain social groups, global communication in general, or specific channels used and their effects on the communication, or the persons using it.
    \n    The environment is experimental, meaning researchers can file new research based on their specific needs via our custom-built research interface and directly impact the behavior of the application for specific users. Including sampling options, functionalities that will be included or functionalities that will be excluded, chatting outcomes expected (thus, what data will be stored), and the period during which research will be conducted. Access to the research interface can be provided to any researcher who is interested in such research.
    \n    It is important to note, that none of the quantitative information is directly accessible by the researcher as the information stored for research is disconnected from the instant messaging database. Neither is the information directly identifiable by legal name, username, exact address, device identifier, or database record identifiers.</string>
  <string name="about_research_options_heading">Options for other researchers</string>
  <string name="about_research_options_content">The works of our team can be re-used not as a prototype as a whole, but into existing projects and prototypes as an SDK (Software Development Kit), which can be implemented into any applications targeting Android, iOS, macOS, Windows, Linux, or Web. It is a bundle of functionalities that can be split into even smaller bundles for specific uses. Such SDKs take advantage of any input available.
    \n    In terms of smartphones, many of the available sensors can be used for interpretation. And while desktop devices lack the number of sensors and thus the ease of interpretation, they can have similarly rich real-time information, such as movements of the mouse, or typing variability.
    \n    Another component that can benefit both commercial and non-commercial projects and applications is an API (Application Programming Interface). Toolset with mostly logic for evaluation, transmission of key information between devices, and other technical aspects of communication online. It is tightly connected to our Interpreter, which builds on both common contents (e.g., text, emojis, reactions, typing time, read/seen), the added cues via additional functionalities, and the context in which it happens. This provides it with a unique insight into interpersonal communication. The outcomes of the Interpreter are then used to further validate and improve the interactions, and to add a layer of understanding for collected study data (such as emoji preference before and after intervention).
    \n    The API also includes a statistical section, which can be used by any third party (e.g., governmental bodies, researchers, statistical tools, intervention developers) for interpretation of the communication online in general.</string>
  <string name="about_research_bibliography_heading">Bibliography</string>
  <string name="about_research_bibliography_content">
    \n1. Two Billion Users — Connecting the World Privately. (2020, February 12). About Facebook. https://about.fb.com/news/2020/02/two-billion-users/
    \n2. Statista. (2023). Most popular messaging apps 2023 | Statista. Statista; Statista. https://www.statista.com/statistics/258749/most-popular-global-mobile-messenger-apps/
    \n3. Karapetyan, A., &amp; Gardner, S. (2023). The Online and Offline Communication Preferences of Armenian Social Network Users. Journal of Sociology: Bulletin of Yerevan University, 14(2 (38)), 66–80. https://doi.org/10.46991/BYSU:F/2023.14.2.066
    \n4. Chung, J. E. (2013). Social interaction in online support groups: Preference for online social interaction over offline social interaction. Computers in Human Behavior, 29(4), 1408–1414. https://doi.org/10.1016/j.chb.2013.01.019
    \n5. Aidi, X. (2009). Cognitive Overload and Its Countermeasures from the Angle of Information Processing. 2009 Third International Symposium on Intelligent Information Technology Application. https://doi.org/10.1109/iita.2009.278
    \n6. Cui, J., Colston, H. L., &amp; Jiang, G. (2024). Is That a Genuine Smile? Emoji-Based Sarcasm Interpretation Across the Lifespan. Metaphor and Symbol, 39(3), 195–216. https://doi.org/10.1080/10926488.2024.2314595
    \n7. Chauhan, D. S., Singh, G. V., Arora, A., Ekbal, A., &amp; Bhattacharyya, P. (2022). An emoji-aware multitask framework for multimodal sarcasm detection. Knowledge-Based Systems, 257, 109924. https://doi.org/10.1016/j.knosys.2022.109924
    \n8. Tran, J., Nguyen, Q. V., Hol, A., &amp; Simoff, S. (2019). Reduction of Cognitive Overload in Online Reviews Using Data Visualisation. Proceedings of the Australasian Computer Science Week Multiconference. https://doi.org/10.1145/3290688.3290708
    \n9. Boutet, I., Guay, J., Chamberland, J., Cousineau, D., &amp; Collin, C. (2022). Emojis that work! Incorporating visual cues from facial expressions in emojis can reduce ambiguous interpretations. Computers in Human Behavior Reports, 100251. https://doi.org/10.1016/j.chbr.2022.100251
    \n10. Rinott, M., &amp; Tractinsky, N. (2021). Designing for interpersonal motor synchronization. Human–Computer Interaction, 1–48. https://doi.org/10.1080/07370024.2021.1912608
    \n11. Buschek, D., Hassib, M., &amp; Alt, F. (2018). Personal Mobile Messaging in Context. ACM Transactions on Computer-Human Interaction, 25(4), 1–33. https://doi.org/10.1145/3201404
  </string>

  <string name="roadmap_heading">Roadmap</string>
  <string name="roadmap_last_update">Last updated 10/18/2024</string>
  <string name="roadmap_description">The estimated timeline for this project. Note that anything on this page is subject to change considering the current stage of the development.</string>
  <string name="roadmap_expand_button">Details</string>

  <string name="roadmap_0_title">Social networking support, 1Q 2025</string>
  <string name="roadmap_0_description">This includes users having the ability to personalize their networks within the application and modify it at any time.</string>
  <string name="roadmap_1_title">Chatting support, 2Q 2025</string>
  <string name="roadmap_1_description">Ability to chat with anyone within the user's network, both in real-time and asynchronously.</string>
  <string name="roadmap_2_title">First experimental functionality 3Q 2025</string>
  <string name="roadmap_2_description">The first experimental functionality is developed and implemented into chatting. The functionality aims to improve expressiveness, and implicity via additional communication cues within interactions and is part of a planned bundle of functionalities we will gradually add.</string>
  <string name="roadmap_3_title">First research, 4Q 2025</string>
  <string name="roadmap_3_description">The first functionality(ies) will be compared to a control group. The research will be conducted to find nuances from its implementation and use. The article will be published in any relevant journal.</string>
  <string name="roadmap_4_title">An initial version of the research interface, 4Q 2025 - 1Q 2026</string>
  <string name="roadmap_4_description">A custom interface allowing for automatic collection and sampling of research, embedded into our product suite. While not widely advertised for researchers, the internal use of the research interface can begin.</string>
  <string name="roadmap_5_title">SDK public release, 1Q 2026 onwards</string>
  <string name="roadmap_5_description">Bundles that are implementable to any existing popular application are being released publicly. Any existing or new application can use our existing logic and improve the quality of communication. The range of functionalities implemented is increasing. The more impactful functionalities are being prioritized and gradually integrated into our application and the SDK bundles.</string>
  <string name="roadmap_6_title">An initial version of Interpreter</string>
  <string name="roadmap_6_description">Even with a minimal user base, our works on Interpreter can be put into practice and directed towards solutions developed within our application, SDK bundles, and research interface.</string>
  <string name="roadmap_7_title">Full functionality support, Q4 2026</string>
  <string name="roadmap_7_description">Our application supports functionality most common to popular instant messaging applications. This provides us with the ability to directly compare the effects of the additional functionalities and modifications we applied so far in contrast to traditional forms of communication.</string>
  <string name="roadmap_8_title">A production version, Q1 2027</string>
  <string name="roadmap_8_description">Our application is ready to be widely published and used by any user who wants to improve the quality of their communication online.</string>

  <string name="delete_me_heading">Data deletion</string>
  <string name="delete_me_description">Are you looking to delete data associated with you? This is the right place. You can either request for a full deletion or just a partial.
    \nFor example, you may want to delete only messages associated with you, your social circle associations, or research data connected to you.
    \nHowever, please note that we delete based on the type of data rather than specific pieces of data. For example, all your messages may be deleted, not just one message.</string>

  <string name="delete_me_user_uid_label">User UID</string>
  <string name="delete_me_user_id_hint">NABWwZun4QPIxYInouchx0dVB8g1</string>
  <string name="delete_me_contents_label">What would you like us to delete?</string>
  <string name="delete_me_contents_hint">All of the cookies</string>
  <string name="delete_me_reason_short_0">It's difficult to understand messages</string>
  <string name="delete_me_reason_short_1">I spend too much time here</string>
  <string name="delete_me_reason_short_2">I don't understand how to use Augmy</string>
  <string name="delete_me_reason_short_3">I use a different account now</string>
  <string name="delete_me_reason_short_4">I prefer regular messaging apps</string>
  <string name="delete_me_reason_short_5">Other</string>
  <string name="delete_me_reason_long_label">Please, explain further if possible</string>
  <string name="delete_me_reason_long_hint">You offer too many cookies but I'm on a diet...</string>
  <string name="delete_me_button_send">Send as an email</string>

  <string name="accessibility_light_mode">Light mode</string>
  <string name="accessibility_dark_mode">Dark mode</string>
  <string name="accessibility_menu">Open side menu</string>
  <string name="accessibility_play_video">Play video</string>
  <string name="accessibility_button_expand">Expand</string>
</resources>